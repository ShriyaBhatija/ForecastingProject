{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a84d64",
   "metadata": {},
   "source": [
    "# Project 2 - Forecasting Service Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3dec46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "afc7e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Reading the data\n",
    "X_KV = pd.read_csv('../X_KV.csv')   #JNSM_KV_flashcrowd_1 \n",
    "Y_KV = pd.read_csv('../Y_KV.csv')   \n",
    "X_VoD = pd.read_csv('../X_VoD.csv') #JNSM_VoD_flashcrowd_1 \n",
    "Y_VoD = pd.read_csv('../Y_VoD.csv') \n",
    "\n",
    "X_KV_2 = pd.read_csv('../X_KV_2.csv')    #JNSM_KV_flashcrowd_2\n",
    "Y_KV_2 = pd.read_csv('../Y_KV_2.csv')    \n",
    "X_VoD_2 = pd.read_csv('../X_VoD_2.csv')  #JNSM_VoD_flashcrowd_2\n",
    "Y_VoD_2 = pd.read_csv('../Y_VoD_2.csv') \n",
    "\n",
    "#Remove the first two columns that index the samples and retrieve all other values by using iloc()\n",
    "X_KV = X_KV.iloc[:,2:]  \n",
    "Y_KV = Y_KV.iloc[:, 2:] \n",
    "X_VoD = X_VoD.iloc[:,2:]\n",
    "Y_VoD = Y_VoD.iloc[:, 2:]\n",
    "\n",
    "X_KV_2 = X_KV_2.iloc[:,2:] \n",
    "Y_KV_2 = Y_KV_2.iloc[:, 2:] \n",
    "X_VoD_2 = X_VoD_2.iloc[:,2:]\n",
    "Y_VoD_2 = Y_VoD_2.iloc[:, 2:]\n",
    "\n",
    "#Concatenate datasets\n",
    "X_KV = pd.concat([X_KV, X_KV_2], ignore_index=True)\n",
    "Y_KV = pd.concat([Y_KV, Y_KV_2], ignore_index=True)\n",
    "X_VoD = pd.concat([X_VoD, X_VoD_2], ignore_index=True)\n",
    "Y_VoD = pd.concat([Y_VoD, Y_VoD_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5321abb",
   "metadata": {},
   "source": [
    "### Task I.4\n",
    "Data preparation: Use one of the methods described in Project 1 (Advanced), Task 1 to pre-process the trace. Remove possible outliers. Reduce the dimensionality of the feature space to k = 16 using tree-based feature selection. Then, split the processed trace into training and test samples (x(t),y(t)) by assigning the samples with t < T to the training set and t ≥ T to the test set. T is chosen so that the training set contains 70% of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0c9b47dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Pre-processing: column-wise standardization \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_KV_columns_scaled = scaler.fit_transform(X_KV)\n",
    "X_KV_columns_scaled = pd.DataFrame(X_KV_columns_scaled)\n",
    "\n",
    "X_VoD_columns_scaled = scaler.fit_transform(X_VoD)\n",
    "X_VoD_columns_scaled = pd.DataFrame(X_VoD_columns_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "929b20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Outlier removal: Threshold that keeps 99% of outliers in the dataset (see Project1 Task IV)\n",
    "\n",
    "#Number of outliers\n",
    "#Use this function to find the threshold that keeps 99% of the samples in the dataset\n",
    "def count(features,thr): \n",
    "    counter = 0\n",
    "    features = features.T\n",
    "    for col in features:\n",
    "        if any(np.absolute(features[col]) >= thr):\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "#For dataset JNSM_KV_flashcrowd 99% of samples correspond to 18.810 samples, i.e. 190 outliers\n",
    "#Choose threshold 69\n",
    "\n",
    "#For dataset JNSM_VoD_flashcrowd_1 99% of samples correspond to 34.650 samples, i.e. 350 outliers\n",
    "#Choose threshold 54\n",
    "\n",
    "# Function that removes outliers from the features matrix as well as the target scores\n",
    "# Note: Input is of the format pd.DataFrame\n",
    "def outlier_detection(features, labels, thr): \n",
    "    features = features.T\n",
    "    for col in features:\n",
    "        if any(np.absolute(features[col]) >= thr):\n",
    "            features = features.drop([col],axis=1)\n",
    "            labels = labels.drop([col],axis=0)\n",
    "    return features.T, labels #Returns reduced feature matrix and target scores\n",
    "\n",
    "X_KV = outlier_detection(X_KV_columns_scaled, Y_KV['ReadsAvg'], 69)[0]\n",
    "Y_KV = outlier_detection(X_KV_columns_scaled, Y_KV['ReadsAvg'], 69)[1]\n",
    "\n",
    "X_VoD = outlier_detection(X_VoD_columns_scaled, Y_VoD['DispFrames'], 54)[0]\n",
    "Y_VoD = outlier_detection(X_VoD_columns_scaled, Y_VoD['DispFrames'], 54)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e1ec50ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 16 features for JNSM_KV_flashcrowd_1: [ 135  229  234  235  385  386  603  655  898  902  991  995  996  997\n",
      " 1717 1718]\n",
      "Top 16 features for JNSM_VoD_flashcrowd_1: [ 490  614  845  879  883  885  939  968  980 1023 1141 1144 1147 1148\n",
      " 1149 1356]\n"
     ]
    }
   ],
   "source": [
    "#3. Dimensionality reducton of the feature space\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#KV service\n",
    "sfm_KV = SelectFromModel(estimator=RandomForestRegressor(n_estimators=10, max_depth = 5), max_features=16).fit(X_KV, Y_KV)\n",
    "sfm_KV.estimator_.feature_importances_\n",
    "feature_index_KV = np.array(range(X_KV.shape[1])) #Features are specified by their position in the design matrix starting from 0\n",
    "\n",
    "print(f\"Top 16 features for JNSM_KV_flashcrowd_1: {feature_index_KV[sfm_KV.get_support()]}\") \n",
    "\n",
    "#Actual names of the top 16 features\n",
    "feature_names_KV = [list(X_KV.columns)[i] for i in feature_index_KV[sfm_KV.get_support()]]\n",
    "\n",
    "#VoD service\n",
    "#Y_VoD_DispFrames = np.array(Y_VoD['DispFrames']).reshape(-1,1) #Values of \"DispFrames\"\n",
    "\n",
    "sfm_VoD = SelectFromModel(estimator=RandomForestRegressor(n_estimators=10, max_depth = 5), max_features=16).fit(X_VoD, Y_VoD)\n",
    "sfm_VoD.estimator_.feature_importances_\n",
    "feature_index_VoD = np.array(range(X_VoD.shape[1]))\n",
    "print(f\"Top 16 features for JNSM_VoD_flashcrowd_1: {feature_index_VoD[sfm_VoD.get_support()]}\")\n",
    "\n",
    "#Actual names of the top 16 features\n",
    "feature_names_VoD = [list(X_VoD.columns)[i] for i in feature_index_VoD[sfm_VoD.get_support()]]\n",
    "\n",
    "#New design matrices reduced to the top 16 features\n",
    "X_KV = sfm_KV.transform(X_KV)\n",
    "X_VoD = sfm_VoD.transform(X_VoD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f2f2505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_KV_train' (ndarray)\n",
      "Stored 'X_KV_test' (ndarray)\n",
      "Stored 'Y_KV_train' (Series)\n",
      "Stored 'Y_KV_test' (Series)\n",
      "Stored 'X_VoD_train' (ndarray)\n",
      "Stored 'X_VoD_test' (ndarray)\n",
      "Stored 'Y_VoD_train' (Series)\n",
      "Stored 'Y_VoD_test' (Series)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_KV_train, X_KV_test, Y_KV_train, Y_KV_test = train_test_split(X_KV, Y_KV, test_size=0.3, shuffle = False)\n",
    "X_VoD_train, X_VoD_test, Y_VoD_train, Y_VoD_test = train_test_split(X_VoD, Y_VoD, test_size=0.3, shuffle = False)\n",
    "\n",
    "%store X_KV_train X_KV_test Y_KV_train Y_KV_test\n",
    "%store X_VoD_train X_VoD_test Y_VoD_train Y_VoD_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e69144",
   "metadata": {},
   "source": [
    "### Task I.5\n",
    "Create a new training set and a new test set with samples of structure ([x(t−l), ..., x(t)], [y(t), ..., y(t+h)])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2bfb2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For KV service\n",
    "def X_KV(samples, l, h):\n",
    "    if (l>=0 and h>0) or (l>0 and h>=0): \n",
    "        matrix = np.empty((samples.shape[0]-l-h,(l+1)*samples.shape[1]))\n",
    "        for i in range(0, samples.shape[0]-h-l):\n",
    "            matrix[i] = np.concatenate([samples[j] for j in range(i,i+l+1)])\n",
    "        return matrix\n",
    "    if l==0 and h==0: \n",
    "        return samples\n",
    "\n",
    "def Y_KV(targets, l, h):\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    if (l>=0 and h>0) or (l>0 and h>=0): \n",
    "        matrix = np.empty((targets.shape[0]-l-h,h+1))   \n",
    "        for i in range(0, targets.shape[0]-h-l):\n",
    "            matrix[i] = np.concatenate([[targets[j]] for j in range(i,i+h+1)])\n",
    "        return matrix\n",
    "    if l==0 and h==0: \n",
    "        return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bd46ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For VoD service\n",
    "def X_VoD(samples, l, h, s):\n",
    "    if s<=0:\n",
    "        print('The step size must be >=1.')\n",
    "        \n",
    "    if (l>=0 and h>0) or (l>0 and h>=0): \n",
    "        matrix = np.empty((samples.shape[0]-s*l-s*h,(l+1)*samples.shape[1]))\n",
    "        for i in range(0, samples.shape[0]-s*l-s*h):\n",
    "            matrix[i] = np.concatenate([samples[j] for j in range(i,i+l*s+1,s)])\n",
    "        return matrix\n",
    "    if l==0 and h==0: \n",
    "        return samples\n",
    "    \n",
    "def Y_VoD(targets, l, h, s):\n",
    "    targets = np.array(targets)\n",
    "    if s<= 0: \n",
    "        print('The step size must be >=1.')\n",
    "        \n",
    "    if (l>=0 and h>0) or (l>0 and h>=0): \n",
    "        matrix = np.empty((targets.shape[0]-s*l-s*h,h+1))   \n",
    "        for i in range(0, targets.shape[0]-s*h-s*l):\n",
    "            matrix[i] = np.concatenate([[targets[j]] for j in range(i,i+s*h+1,s)])\n",
    "        return matrix\n",
    "    if l==0 and h==0: \n",
    "        return targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad8b75a",
   "metadata": {},
   "source": [
    "### Task I.7\n",
    "Using linear regression, train models for l = 0, .., 10 in the feature space and h = 0, .., 10 in the target space. The model with l = 0 corresponds to prediction using the current sample. A model with l > 0 corresponds to learning on l samples into the past and predicting 0, ..., 10 steps into the future. Evaluate the models by computing the error (NMAE) on the test set. Display the results in a table with rows representing the time horizon h = 0, .., 10 and columns representing the lag l = 0, .., 10. You need to train one model for each lag value (11 models in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0fb94424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "00cdf623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KV service\n",
    "\n",
    "#Function that trains a model given the lag value \n",
    "def prediction_KV(l):\n",
    "    reg = LinearRegression(fit_intercept=True).fit(X_KV(X_KV_train, l, 10),Y_KV(Y_KV_train, l, 10))                                                \n",
    "    return reg.predict(X_KV(X_KV_test, l, 10))\n",
    "\n",
    "#Function that outputs the NMAE for a given horizon value\n",
    "#Outputs array of shape (,11), at each position there is the nmae for the respective lag value\n",
    "def errors_KV(h):\n",
    "    if h in range(0,11):\n",
    "        errors = np.empty(11)\n",
    "        for l in range(0,11):\n",
    "            errors[l] = (1/np.mean(Y_KV(Y_KV_test,l,10)[:,:h+1]))*mean_absolute_error(prediction_KV(l)[:,:h+1],Y_KV(Y_KV_test,l,10)[:,:h+1])\n",
    "        return errors\n",
    "    else: \n",
    "        print('Horizon value needs to be 0,...,10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a12dc8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VoD service \n",
    "\n",
    "#Choosing s = 30\n",
    "\n",
    "#Function that trains a model given the lag value\n",
    "def prediction_VoD(l):\n",
    "    reg = LinearRegression(fit_intercept=True).fit(X_VoD(X_VoD_train, l, 10, 30),Y_VoD(Y_VoD_train, l, 10, 30))                                                \n",
    "    return reg.predict(X_VoD(X_VoD_test, l, 10, 30))\n",
    "\n",
    "#Function that outputs the NMAE for a given horizon value\n",
    "#Outputs array of shape (,11), at each position there is the nmae for the respective lag value\n",
    "def errors_VoD(h):\n",
    "    if h in range(0,11):\n",
    "        errors = np.empty(11)\n",
    "        for l in range(0,11):\n",
    "            errors[l] = (1/np.mean(Y_VoD(Y_VoD_test,l,10,30)[:,:h+1]))*mean_absolute_error(prediction_VoD(l)[:,:h+1],Y_VoD(Y_VoD_test,l,10,30)[:,:h+1])\n",
    "        return errors\n",
    "    else: \n",
    "        print('Horizon value needs to be 0,...,10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3fcff9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matrices for each service that display the NMAE given h = 0,1,...,10 (rows) and l = 0,1,...,10 (columns)\n",
    "\n",
    "error_matrix_KV = []\n",
    "error_matrix_VoD = []\n",
    "for h in range(0,11):\n",
    "    error_matrix_KV.append(errors_KV(h))\n",
    "    error_matrix_VoD.append(errors_VoD(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7cd5f6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrrrrr}\n",
      "\\hline\n",
      " 2158 & 2195 & 2181 & 2184 & 2171 & 2157 & 2155 & 2151 & 2151 & 2138 & 2138 \\\\\n",
      " 2144 & 2183 & 2186 & 2179 & 2173 & 2159 & 2153 & 2149 & 2147 & 2140 & 2135 \\\\\n",
      " 2128 & 2162 & 2181 & 2181 & 2172 & 2163 & 2154 & 2148 & 2145 & 2139 & 2136 \\\\\n",
      " 2123 & 2147 & 2167 & 2179 & 2175 & 2164 & 2158 & 2150 & 2145 & 2139 & 2136 \\\\\n",
      " 2138 & 2142 & 2155 & 2168 & 2172 & 2166 & 2158 & 2152 & 2145 & 2139 & 2135 \\\\\n",
      " 2165 & 2153 & 2149 & 2157 & 2163 & 2162 & 2158 & 2150 & 2145 & 2138 & 2133 \\\\\n",
      " 2197 & 2176 & 2158 & 2152 & 2153 & 2155 & 2154 & 2149 & 2143 & 2137 & 2132 \\\\\n",
      " 2226 & 2201 & 2177 & 2159 & 2147 & 2145 & 2146 & 2144 & 2140 & 2134 & 2129 \\\\\n",
      " 2259 & 2230 & 2202 & 2177 & 2155 & 2142 & 2139 & 2139 & 2138 & 2133 & 2128 \\\\\n",
      " 2288 & 2261 & 2229 & 2200 & 2172 & 2149 & 2136 & 2133 & 2133 & 2130 & 2126 \\\\\n",
      " 2316 & 2289 & 2258 & 2226 & 2194 & 2166 & 2144 & 2131 & 2129 & 2127 & 2124 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{rrrrrrrrrrr}\n",
      "\\hline\n",
      " 1292 & 1303 & 1294 & 1299 & 1298 & 1310 & 1314 & 1321 & 1329 & 1339 & 1350 \\\\\n",
      " 1291 & 1290 & 1293 & 1288 & 1292 & 1298 & 1306 & 1314 & 1321 & 1329 & 1339 \\\\\n",
      " 1328 & 1290 & 1291 & 1292 & 1290 & 1296 & 1301 & 1311 & 1319 & 1326 & 1334 \\\\\n",
      " 1369 & 1305 & 1289 & 1288 & 1290 & 1291 & 1296 & 1303 & 1313 & 1320 & 1328 \\\\\n",
      " 1407 & 1335 & 1303 & 1286 & 1286 & 1290 & 1292 & 1299 & 1307 & 1315 & 1323 \\\\\n",
      " 1443 & 1375 & 1333 & 1298 & 1284 & 1286 & 1290 & 1295 & 1303 & 1310 & 1319 \\\\\n",
      " 1472 & 1413 & 1370 & 1324 & 1294 & 1285 & 1288 & 1294 & 1299 & 1306 & 1314 \\\\\n",
      " 1494 & 1445 & 1408 & 1360 & 1320 & 1296 & 1288 & 1293 & 1299 & 1304 & 1312 \\\\\n",
      " 1511 & 1472 & 1440 & 1397 & 1355 & 1320 & 1298 & 1293 & 1299 & 1304 & 1310 \\\\\n",
      " 1518 & 1490 & 1464 & 1426 & 1389 & 1351 & 1319 & 1301 & 1299 & 1304 & 1310 \\\\\n",
      " 1525 & 1503 & 1484 & 1451 & 1418 & 1384 & 1349 & 1321 & 1307 & 1304 & 1309 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "#Obtain Latex code \n",
    "\n",
    "import tabulate\n",
    "from tabulate import tabulate\n",
    "\n",
    "np.set_printoptions(precision=0)\n",
    "error_matrix_KV = np.array(error_matrix_KV)*10000\n",
    "error_matrix_VoD = np.array(error_matrix_VoD)*10000\n",
    "\n",
    "print(tabulate(error_matrix_KV, tablefmt=\"latex\", floatfmt=\".0f\"))\n",
    "print(tabulate(error_matrix_VoD, tablefmt=\"latex\", floatfmt=\".0f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
