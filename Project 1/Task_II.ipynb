{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9656d57a",
   "metadata": {},
   "source": [
    "## Project 1 - Task II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef0884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 00:53:09.727061: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.layers import LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74894ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing results from Task I \n",
    "%run Task_I.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c7518",
   "metadata": {},
   "source": [
    "### Task 2.1 \n",
    "Model Training: Train three models M1,M2,M3 on the training set (produced in Task I-3) using the methods linear regression, random forest regression, and neural network regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#M1: Fitting Linear Regression\n",
    "reg_KV = LinearRegression(fit_intercept=True).fit(X_KV_new, Y_KV['ReadsAvg'])  \n",
    "reg_VoD = LinearRegression(fit_intercept=True).fit(X_VoD_new, Y_VoD['DispFrames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01422dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using RandomizedSearchCV in order to find good hyperparameters for Random Forest\n",
    "rand_forest = RandomForestRegressor()\n",
    "dist_rand_forest = dict(n_estimators = range(1,50), max_depth=range(1,10))\n",
    "\n",
    "rand_forest_hyp_KV = RandomizedSearchCV(estimator = rand_forest, param_distributions = dist_rand_forest,n_iter=20)\n",
    "hyp_KV = rand_forest_hyp_KV.fit(X_KV_new, Y_KV['ReadsAvg'])\n",
    "hyp_KV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13211acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest_hyp_VoD = RandomizedSearchCV(estimator = rand_forest, param_distributions = dist_rand_forest,n_iter=20)\n",
    "hyp_VoD = rand_forest_hyp_VoD.fit(X_VoD_new, Y_VoD['DispFrames'])\n",
    "hyp_VoD.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89322142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Random Forest with best found hyperparameters\n",
    "rand_forest_KV = RandomForestRegressor(n_estimators = 39, max_depth=8).fit(X_KV_new, Y_KV['ReadsAvg'])\n",
    "rand_forest_VoD = RandomForestRegressor(n_estimators = 45, max_depth=4).fit(X_VoD_new,Y_VoD['DispFrames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train NN using hyperparameters obtained from trial and error\n",
    "\n",
    "#Define a base model:\n",
    "def baseline_model():\n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=32, input_shape=(16,),activation = 'relu'))\n",
    "    model.add(Dense(units=16,activation = 'relu'))\n",
    "    model.add(Dense(units=8,activation = 'relu'))\n",
    "    model.add(Dense(1))\n",
    "    #Compile model\n",
    "    model.compile(loss='mse', optimizer = keras.optimizers.Adam(learning_rate=1e-5), metrics = [tf.keras.metrics.MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "#Early Stopping to avoid overfitting\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta = 0.005, patience=500) #Early stopping to avoid overfitting\n",
    "\n",
    "NN_KV_ReadsAvg = KerasRegressor(model=baseline_model(), epochs=5000, batch_size=300, callbacks = [callback])\n",
    "NN_KV_ReadsAvg.fit(X_KV_new, Y_KV['ReadsAvg'])\n",
    "\n",
    "NN_VoD = KerasRegressor(model=baseline_model(), epochs=5000, batch_size=300, verbose=0, callbacks = [callback])\n",
    "NN_VoD.fit(features_VoD_new, Y_VoD['DispFrames'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25841e37",
   "metadata": {},
   "source": [
    "### Task 2.2\n",
    "Train and test your models Mi with the so-called validation-set technique. This technique entails that you split the set of observations into two parts: the training set for computing the model Mi and the test set for evaluating the accuracy of Mi. From the complete set of observations, you select uniformly at random 70% of the observations to form the training set and then assign the remaining 30% to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f735212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into test and training \n",
    "\n",
    "#Store reduces feature matrices and target scores in pd.Dataframe s.t. we can sort after indices \n",
    "X_KV_new = pd.DataFrame(X_KV_new)\n",
    "X_VoD_new = pd.DataFrame(X_VoD_new)\n",
    "\n",
    "X_KV_train, X_KV_test, Y_KV_train, Y_KV_test = train_test_split(X_KV_new, Y_KV['ReadsAvg'], test_size=0.3, random_state=42)\n",
    "X_VoD_train, X_VoD_test, Y_VoD_train, Y_VoD_test = train_test_split(X_VoD_new, Y_VoD['DispFrames'], test_size=0.3, random_state=42)\n",
    "\n",
    "#Store train and test sets sorted after index\n",
    "X_KV_train =  X_KV_train.sort_index(axis=0)\n",
    "X_KV_test = X_KV_test.sort_index(axis=0)\n",
    "Y_KV_train = Y_KV_train.sort_index(axis=0)\n",
    "Y_KV_test = Y_KV_test.sort_index(axis=0)\n",
    "\n",
    "X_VoD_train = X_VoD_train.sort_index(axis=0)\n",
    "X_VoD_test = X_VoD_test.sort_index(axis=0)\n",
    "Y_VoD_train = Y_VoD_train.sort_index(axis=0)\n",
    "Y_VoD_test = Y_VoD_test.sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9616499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Linear Regression on the training set\n",
    "reg_KV = LinearRegression(fit_intercept=True).fit(X_KV_train, Y_KV_train) #Train on the training set\n",
    "reg_KV_pred = reg_KV.predict(X_KV_test)\n",
    "\n",
    "reg_VoD = LinearRegression(fit_intercept=True).fit(X_VoD_train, Y_VoD_train)\n",
    "reg_VoD_pred = reg_VoD.predict(X_VoD_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using RandomizedSearchCV in order to find good hyperparameters for Random Forest\n",
    "rand_forest_hyp_KV = RandomizedSearchCV(estimator = rand_forest, param_distributions = dist_rand_forest)\n",
    "hyp_KV = rand_forest_hyp_KV.fit(X_KV_train, Y_KV_train)\n",
    "hyp_KV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8885ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest_hyp_VoD = RandomizedSearchCV(estimator = rand_forest, param_distributions = dist_rand_forest)\n",
    "hyp_VoD = rand_forest_hyp_KV.fit(X_VoD_train, Y_VoD_train)\n",
    "hyp_VoD.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cdc35a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Random Forest with best found hyperparameters on the training set\n",
    "rand_forest_KV = RandomForestRegressor(n_estimators = 15, max_depth=6).fit(X_KV_train, Y_KV_train)\n",
    "rand_forest_KV_pred = rand_forest_KV.predict(X_KV_test)\n",
    "\n",
    "rand_forest_VoD = RandomForestRegressor(n_estimators = 16, max_depth=9).fit(X_VoD_train, Y_VoD_train)\n",
    "rand_forest_VoD_pred = rand_forest_VoD.predict(X_VoD_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c31a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using MLPRegressor() and RandomizedSearchCV() find good hyperparameters for NN\n",
    "NN = MLPRegressor(solver='adam', tol=2, max_iter=100)\n",
    "\n",
    "hidden_layer_sizes = [(int(x),int(y),int(z)) for x in range(1,64) for y in range(1,32) for z in range(1,16) ]\n",
    "activation = ['logistic', 'tanh', 'relu']\n",
    "dist_NN = {'activation': activation,  'hidden_layer_sizes': hidden_layer_sizes}\n",
    "\n",
    "NN_KV = RandomizedSearchCV(estimator = NN, param_distributions = dist_NN)\n",
    "hyp_KV = NN_KV.fit(X_KV_train, Y_KV_train)\n",
    "hyp_KV.best_params_\n",
    "\n",
    "#Output = {'hidden_layer_sizes': (63, 26, 14), 'activation': 'relu'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3fb6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_VoD = RandomizedSearchCV(estimator = NN, param_distributions = dist_NN)\n",
    "hyp_VoD = NN_KV.fit(X_VoD_train, Y_VoD_train)\n",
    "hyp_KV.best_params_\n",
    "\n",
    "#Output = {'hidden_layer_sizes': (13, 14, 10), 'activation': 'logistic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485322fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train NN for target score ReadsAvg\n",
    "\n",
    "#hyperparameters through formal search and a lot of trial and error\n",
    "def baseline_model(lr):\n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=32, input_shape=(16,),activation='relu'))\n",
    "    model.add(Dense(units=16, activation='relu'))\n",
    "    model.add(Dense(units=8, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    #Compile model\n",
    "    model.compile(loss='mae', optimizer = keras.optimizers.Adam(learning_rate=lr), metrics = [tf.keras.metrics.MeanAbsoluteError()])\n",
    "    return model\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta = 0.005, patience=20) #Early stopping to avoid overfitting\n",
    "\n",
    "NN_KV_ReadsAvg = KerasRegressor(model=baseline_model(1e-4), epochs=5000, batch_size=300, callbacks = [callback]).fit(X_KV_train, Y_KV_train)\n",
    "NN_KV_ReadsAvg_pred = NN_KV_ReadsAvg.predict(X_KV_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828da658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train NN for target score DispFrames\n",
    "\n",
    "def baseline_model(lr):\n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=13, input_shape=(16,),activation='relu'))\n",
    "    model.add(Dense(units=14, activation='tanh'))\n",
    "    model.add(Dense(units=10, activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "    #Compile model\n",
    "    model.compile(loss='mae', optimizer = keras.optimizers.Adam(learning_rate=lr), metrics = [tf.keras.metrics.MeanAbsoluteError()])\n",
    "    return model\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',min_delta = 0.01, patience=50)\n",
    "\n",
    "NN_VoD = KerasRegressor(model=baseline_model(1e-3), epochs=5000, batch_size=300 ,callbacks=[callback]).fit(X_VoD_train, Y_VoD_train)\n",
    "NN_VoD_pred = NN_VoD.predict(X_VoD_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca0ff3a",
   "metadata": {},
   "source": [
    "### Task 2.3\n",
    "Model Accuracy: Compute the estimation error of the models Mi on the test set. We define the estimation error as the Normalized Mean Absolute Error (NMAE) = 1(1 􏰂m |yj −yˆj|), whereby\n",
    "y ̄m j=1\n",
    "yˆj is the model estimation for the measured service metric yi, and y ̄ is the average of the observations\n",
    "yj of the test set. Note that yˆj = Mi(yj)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "899a862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019578755791714635\n",
      "0.11128603229548305\n"
     ]
    }
   ],
   "source": [
    "#Model 1: Linear Regression\n",
    "\n",
    "#NMAE for Dataset 1:  \n",
    "NMAE_KV_reg = (1/Y_KV_test.mean())*mean_absolute_error(Y_KV_test, reg_KV_pred)\n",
    "print(NMAE_KV_reg)\n",
    "\n",
    "#NMAE for Dataset 2: \n",
    "NMAE_VoD_reg = (1/Y_VoD_test.mean())*mean_absolute_error(Y_VoD_test, reg_VoD_pred)\n",
    "print(NMAE_VoD_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ebcdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017444648428940827\n",
      "0.08205953150784659\n"
     ]
    }
   ],
   "source": [
    "#Model 2: Random Forest\n",
    "\n",
    "#NMAE for Dataset 1: \n",
    "NMAE_KV_rand_forest = (1/Y_KV_test.mean())*mean_absolute_error(Y_KV_test, rand_forest_KV_pred)\n",
    "print(NMAE_KV_rand_forest)\n",
    "\n",
    "#NMAE for Dataset 2: \n",
    "NMAE_VoD_rand_forest = (1/Y_VoD_test.mean())*mean_absolute_error(Y_VoD_test, rand_forest_VoD_pred)\n",
    "print(NMAE_VoD_rand_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3: Neural Network\n",
    "\n",
    "#NMAE for Dataset 1: \n",
    "NMAE_KV_NN = (1/Y_KV_test.mean())*mean_absolute_error(Y_KV_test, NN_KV_ReadsAvg_pred)\n",
    "print(NMAE_KV_NN)\n",
    "\n",
    "#NMAE for Dataset 2:\n",
    "NMAE_VoD_NN = (1/Y_VoD_test.mean())*mean_absolute_error(Y_VoD_test, NN_VoD_pred)\n",
    "print(NMAE_VoD_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d5aef8",
   "metadata": {},
   "source": [
    "### Task 2.5\n",
    "As a baseline for Mi, use a na ̈ıve method which relies on Y values only. For each x ∈ X it predicts a constant value y ̄ which is the mean of the samples yj in the training set. Compute y ̄ for the na ̈ıve method for the training set and compute the NMAE for the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80dc43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For target score ReadsAvg of Dataset 1\n",
    "mean_KV_ReadsAvg = np.full(shape=X_KV_test.shape[0],fill_value=np.mean(Y_KV_train)) #Array containing mean of target values in the training set\n",
    "NMAE_KV_ReadsAvg = (1/np.mean(Y_KV_test))*mean_absolute_error(Y_KV_test, mean_KV_ReadsAvg)\n",
    "\n",
    "#For target score DispFrames of Dataset 2\n",
    "mean_VoD_DispFrames = np.full(shape=X_VoD_test.shape[0],fill_value=np.mean(Y_VoD_train))\n",
    "NMAE_VoD_DispFrames = (1/np.mean(Y_VoD_test))*mean_absolute_error(Y_VoD_test, mean_VoD_DispFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe058a",
   "metadata": {},
   "source": [
    "### Task 2.6\n",
    "Choose one method (either linear regression, random forest, or neural network) and produce a time series plot that shows both the measurements and the model estimations for the target on the test set. Show also the prediction of the a na ̈ıve method (see Figure 1). For this plot chose a time interval with 1 000 samples of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e04f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time series for estimations of the method Linear Regression\n",
    "\n",
    "# For ReadsAvg Values\n",
    "plt.figure(figsize=(16, 3))\n",
    "plt.plot(range(1000), Y_KV_test.iloc[:1000], linewidth=0.8, color='r', label='Measured')\n",
    "plt.plot(range(1000), reg_KV_pred[:1000], linewidth=1.2, color='b', label='Estimated')\n",
    "plt.plot(range(1000), mean_KV_ReadsAvg[:1000], linewidth=1.5, color='black', label='Naive Estimation')\n",
    "plt.ylim([50,70])\n",
    "plt.xlabel('Time Index',fontsize=16)\n",
    "plt.ylabel('ReadsAvg',fontsize=16)\n",
    "#plt.title(\"Times series plot for the target score 'ReadsAvg' corresponding to the dataset JNSM_KV_flashcrowd_1\",fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "#plt.savefig('time_series_KV',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#For DispFrames Values\n",
    "plt.figure(figsize=(16, 3))\n",
    "plt.plot(range(1000), Y_VoD_test[:1000], linewidth=0.8, color='r', label='Measured')\n",
    "plt.plot(range(1000), reg_VoD_pred[:1000], linewidth=1.2, color='blue', label='Estimated')\n",
    "plt.plot(range(1000), mean_VoD_DispFrames[:1000], linewidth=1.5, color='black', label='Naive Estimation')\n",
    "plt.ylim([0,30])\n",
    "plt.xlabel('Time Index',fontsize=16)\n",
    "plt.ylabel('DispFrames',fontsize=16)\n",
    "#plt.title(\"Times series plot for the target score 'DispFrames' corresponding to the dataset JNSM_VoD_flashcrowd_1\",fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "#plt.savefig('time_series_VoD',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91481219",
   "metadata": {},
   "source": [
    "### Task 2.7\n",
    "Produce a density plot and a histogram for the target values on the test set. Set the bin size of the histogram to 1 frame for Video Frame Rate or 1ms for Response Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0495b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For target score ReadsAvg\n",
    "hist_KV_ReadsAvg = sns.distplot(Y_KV_test.iloc[:], hist=True, kde=True, \n",
    "             bins=25, color = 'lightblue', \n",
    "             hist_kws={'edgecolor':'red', 'linewidth': 3},\n",
    "             kde_kws={'color': 'black','linewidth': 2, 'label': 'ReadsAvg' })\n",
    "\n",
    "plt.xlabel(\"ReadsAvg\",fontsize=16)\n",
    "plt.ylabel(\"Density\",fontsize=16)\n",
    "#plt.legend()\n",
    "#plt.title(\"Density for values 'ReadsAvg' on the test set\") \n",
    "plt.xlim([50, 65])\n",
    "#plt.savefig('hist_y_KV',bbox_inches='tight')\n",
    "plt.show(hist_KV_ReadsAvg)\n",
    "\n",
    "\n",
    "#For target score DispFrames\n",
    "hist_VoD_DispFrames = sns.distplot(Y_VoD_test, hist=True, kde=True, \n",
    "             bins=int(20), color = 'lightblue', \n",
    "             hist_kws={'edgecolor':'red', 'linewidth': 3},\n",
    "             kde_kws={'color': 'black','linewidth': 2, 'label': 'DispFrames' })\n",
    "\n",
    "plt.xlabel('DispFrames',fontsize=16)\n",
    "plt.ylabel(\"Density\",fontsize=16)\n",
    "#plt.legend()\n",
    "#plt.title(\"Density for values 'DispFrames' on the test set\") \n",
    "plt.xlim([10, 26])\n",
    "#plt.savefig('hist_y_VoD',bbox_inches='tight')\n",
    "plt.show(hist_VoD_DispFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b42385",
   "metadata": {},
   "source": [
    "### Task 2.8\n",
    "Produce a density plot of the estimation errors yj − yˆj in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For target values ReadsAvg\n",
    "\n",
    "reg_KV_ReadsAvg_err = pd.DataFrame(np.absolute(Y_KV_test.iloc[:]-reg_KV_pred[:]), columns = ['ReadsAvg'])\n",
    "reg_KV_ReadsAvg_err.plot(kind=\"density\")\n",
    "plt.title(\"Linear Regression\",fontsize=26) \n",
    "#plt.xlabel(\"Absolute error\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlim([-5, 30])\n",
    "plt.savefig('Reg1', bbox_inches='tight')\n",
    "\n",
    "rand_forest_KV_ReadsAvg_err = pd.DataFrame(np.absolute(Y_KV_test.iloc[:].values-rand_forest_KV_pred[:]), columns = ['ReadsAvg'])\n",
    "rand_forest_KV_ReadsAvg_err.plot.density()\n",
    "plt.title(\"Random Forest\", fontsize=26) \n",
    "#plt.xlabel(\"Absolute error\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlim([-5, 30])\n",
    "plt.savefig('Rand1', bbox_inches='tight')\n",
    "\n",
    "NN_KV_ReadsAvg_err = pd.DataFrame(np.absolute(Y_KV_test.iloc[:].values-NN_KV_ReadsAvg_pred.reshape(-1,1)), columns = ['ReadsAvg'])\n",
    "NN_KV_ReadsAvg_err.plot.density()\n",
    "plt.title(\"Estimation error using Neuran Network\") \n",
    "plt.xlabel(\"Absolute error\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.xlim([0, 30])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For DispFrames\n",
    "\n",
    "reg_VoD_err = pd.DataFrame(np.absolute(Y_VoD_test.iloc[:].values-reg_VoD_pred), columns = ['DispFrames'])\n",
    "reg_VoD_err.plot.density()\n",
    "plt.title(\"Linear Regression\",fontsize=26) \n",
    "#plt.xlabel(\"Absolute error\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlim([-5, 30])\n",
    "plt.savefig('Reg3', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "rand_forest_VoD_err = pd.DataFrame(np.absolute(Y_VoD_test.iloc[:].values-rand_forest_VoD_pred.flatten()), columns = ['DispFrames'])\n",
    "rand_forest_VoD_err.plot.density()\n",
    "plt.title(\"Random Forest\", fontsize=26) \n",
    "#plt.xlabel(\"Absolute error\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlim([-5, 30])\n",
    "plt.savefig('Rand3', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "NN_VoD_err = pd.DataFrame(np.absolute(Y_VoD_test.iloc[:].values-NN_VoD_pred.reshape(-1,1)), columns = ['DispFrames'])\n",
    "NN_VoD_err.plot.density()\n",
    "plt.title(\"Estimation error using Neuran Network\") \n",
    "plt.xlabel(\"Absolute error\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.xlim([-5, 30])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
